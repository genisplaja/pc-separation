{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68db8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import libtsm\n",
    "from madmom.features.onsets import CNNOnsetProcessor\n",
    "from madmom.features.beats import RNNBeatProcessor\n",
    "from madmom.features.downbeats import RNNDownBeatProcessor\n",
    "from synctoolbox.dtw.mrmsdtw import sync_via_mrmsdtw\n",
    "from synctoolbox.dtw.utils import compute_optimal_chroma_shift, shift_chroma_vectors, make_path_strictly_monotonic\n",
    "from synctoolbox.feature.chroma import pitch_to_chroma, quantize_chroma, quantized_chroma_to_CENS\n",
    "from synctoolbox.feature.pitch import audio_to_pitch_features\n",
    "from synctoolbox.feature.utils import estimate_tuning\n",
    "\n",
    "\n",
    "MADMOM_Fs = 44100\n",
    "MADMOM_FEATURE_RATE = 100\n",
    "\n",
    "SYNCTOOLBOX_Fs = 22050\n",
    "SYNCTOOLBOX_FEATURE_RATE = 50\n",
    "STEP_WEIGHTS = np.array([1.5, 1.5, 2.0])\n",
    "THRESHOLD_REC = 10 ** 6\n",
    "\n",
    "# This should be initiated by the user. \n",
    "PIANO_FILEPATH = 'sync_test/audio/piano/BeethovenLiszt_Op021-03_Katsaris_YT.wav'\n",
    "ORCH_FILEPATH = 'sync_test/audio/orchestra/Beethoven_Op021-03_MarineChamberOrchestra_IMSLP.wav'\n",
    "OUT_DIR = 'sync_test/sync'\n",
    "\n",
    "if not os.path.isdir(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63819cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_signal(x_in, \n",
    "                    Fs_in, \n",
    "                    Fs_out=100, \n",
    "                    norm=True, \n",
    "                    time_max_sec=None, \n",
    "                    sigma=None):\n",
    "    if sigma is not None:\n",
    "        x_in = ndimage.gaussian_filter(x_in, sigma=sigma)\n",
    "    \n",
    "    T_coef_in = np.arange(x_in.shape[0]) / Fs_in\n",
    "    time_in_max_sec = T_coef_in[-1]\n",
    "    \n",
    "    if time_max_sec is None:\n",
    "        time_max_sec = time_in_max_sec\n",
    "        \n",
    "    N_out = int(np.ceil(time_max_sec*Fs_out))\n",
    "    T_coef_out = np.arange(N_out) / Fs_out\n",
    "    \n",
    "    if T_coef_out[-1] > time_in_max_sec:\n",
    "        x_in = np.append(x_in, [0])\n",
    "        T_coef_in = np.append(T_coef_in, [T_coef_out[-1]])\n",
    "    x_out = interp1d(T_coef_in, x_in, kind='linear')(T_coef_out)\n",
    "    \n",
    "    if norm:\n",
    "        x_max = max(x_out)\n",
    "        if x_max > 0:\n",
    "            x_out = x_out / max(x_out)\n",
    "            \n",
    "    return x_out, Fs_out\n",
    "\n",
    "\n",
    "def get_chroma_features(audio,\n",
    "                        tuning_offset,\n",
    "                        Fs=SYNCTOOLBOX_Fs,\n",
    "                        feature_rate=SYNCTOOLBOX_FEATURE_RATE,\n",
    "                        verbose=False):\n",
    "    f_pitch = audio_to_pitch_features(f_audio=audio,\n",
    "                                      Fs=Fs,\n",
    "                                      tuning_offset=tuning_offset,\n",
    "                                      feature_rate=feature_rate,\n",
    "                                      verbose=verbose)\n",
    "    f_chroma = pitch_to_chroma(f_pitch=f_pitch)\n",
    "    f_chroma_quantized = quantize_chroma(f_chroma=f_chroma)\n",
    "\n",
    "    return f_chroma_quantized\n",
    "\n",
    "\n",
    "def get_act_function(act_processor,\n",
    "                     audio,\n",
    "                     feature_sequence_length,\n",
    "                     orig_feature_rate=MADMOM_FEATURE_RATE,\n",
    "                     target_feature_rate=SYNCTOOLBOX_FEATURE_RATE,\n",
    "                     sr=MADMOM_Fs):\n",
    "    \n",
    "    # The original feature rate by processors is 100 fps per default.\n",
    "    act_function = act_processor(audio)\n",
    "    \n",
    "    # For downbeat activation functions\n",
    "    if act_function.ndim == 2:\n",
    "        act_function = act_function[:, 1]\n",
    "    \n",
    "    # The output signal has to be interpolated to the \n",
    "    f_novelty, Fs_out = resample_signal(act_function, \n",
    "                                        Fs_in=orig_feature_rate, \n",
    "                                        Fs_out=target_feature_rate)\n",
    "    \n",
    "    if f_novelty.size < feature_sequence_length:\n",
    "        # The feature sequence length of the chroma features is not the same as the novelty curve\n",
    "        # due to the padding while the computation of STFT for chroma features and the differentiation in spectral flux.\n",
    "        diff = feature_sequence_length - f_novelty.size\n",
    "        if diff % 2 == 0:\n",
    "            pad = int(diff / 2)\n",
    "            f_novelty = np.concatenate((np.zeros(pad), f_novelty, np.zeros(pad)))\n",
    "        else:\n",
    "            pad = int(diff / 2)\n",
    "            f_novelty = np.concatenate((np.zeros(pad), f_novelty, np.zeros(pad)))\n",
    "            null_to_append = np.array([0])\n",
    "            f_novelty = np.append(f_novelty, null_to_append)\n",
    "    \n",
    "    return f_novelty.reshape(1, -1)\n",
    "\n",
    "\n",
    "def get_obd_act_function(audio,\n",
    "                         feature_sequence_length,\n",
    "                         madmom_feature_rate=MADMOM_FEATURE_RATE,\n",
    "                         sync_feature_rate=SYNCTOOLBOX_FEATURE_RATE,\n",
    "                         madmom_sr=MADMOM_Fs):\n",
    "    \n",
    "    onset_processor = CNNOnsetProcessor(fps=madmom_feature_rate, sr=madmom_sr)\n",
    "    beat_processor = RNNBeatProcessor(fps=madmom_feature_rate, sr=madmom_sr)\n",
    "    downbeat_processor = RNNDownBeatProcessor(fps=madmom_feature_rate, sr=madmom_sr)\n",
    "    \n",
    "    f_onset = get_act_function(act_processor=onset_processor,\n",
    "                               audio=audio,\n",
    "                               feature_sequence_length=feature_sequence_length,\n",
    "                               orig_feature_rate=madmom_feature_rate,\n",
    "                               target_feature_rate=sync_feature_rate,\n",
    "                               sr=madmom_sr)\n",
    "\n",
    "    f_beat = get_act_function(act_processor=beat_processor,\n",
    "                              audio=audio,\n",
    "                              feature_sequence_length=feature_sequence_length,\n",
    "                              orig_feature_rate=madmom_feature_rate,\n",
    "                              target_feature_rate=sync_feature_rate,\n",
    "                              sr=madmom_sr)\n",
    "\n",
    "    f_downbeat = get_act_function(act_processor=downbeat_processor,\n",
    "                                  audio=audio,\n",
    "                                  feature_sequence_length=feature_sequence_length,\n",
    "                                  orig_feature_rate=madmom_feature_rate,\n",
    "                                  target_feature_rate=sync_feature_rate,\n",
    "                                  sr=madmom_sr)\n",
    "    \n",
    "    f_onset = np.reshape(f_onset, f_onset.shape[1])\n",
    "    f_beat = np.reshape(f_beat, f_beat.shape[1])\n",
    "    f_downbeat = np.reshape(f_downbeat, f_downbeat.shape[1])\n",
    "    \n",
    "    f_obd = np.array([f_onset, f_beat, f_downbeat])  \n",
    "    \n",
    "    return f_obd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a74b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(audio_44k,\n",
    "                     madmom_sr=MADMOM_Fs,\n",
    "                     sync_sr=SYNCTOOLBOX_Fs):\n",
    "    \n",
    "    # Resample for synchronization \n",
    "    audio_22k = librosa.resample(audio_44k, \n",
    "                                 orig_sr=MADMOM_Fs, \n",
    "                                 target_sr=SYNCTOOLBOX_Fs)\n",
    "    # Estimate tuning for the chroma features\n",
    "    tuning_offset = estimate_tuning(audio_22k, SYNCTOOLBOX_Fs)\n",
    "    \n",
    "    # Compute chroma features\n",
    "    f_chroma = get_chroma_features(audio_22k, \n",
    "                                   tuning_offset)\n",
    "\n",
    "    f_obd = get_obd_act_function(audio_44k,\n",
    "                                 feature_sequence_length=f_chroma.shape[1])   \n",
    "\n",
    "    return f_chroma, f_obd\n",
    "    \n",
    "# Load the orchestra audio file\n",
    "orch, _ = librosa.load(ORCH_FILEPATH, sr=MADMOM_Fs)\n",
    "\n",
    "# Load the piano audio file\n",
    "piano, _ = librosa.load(PIANO_FILEPATH, sr=MADMOM_Fs)\n",
    "\n",
    "# Compute features\n",
    "orch_chroma, orch_obd = compute_features(orch)\n",
    "piano_chroma, piano_obd = compute_features(piano)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c172d6-7fc6-44dc-8066-5265f465cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal chroma shift and shift chroma vectors if needed\n",
    "f_cens_1hz_orch = quantized_chroma_to_CENS(orch_chroma, 201, 50, SYNCTOOLBOX_FEATURE_RATE)[0]\n",
    "f_cens_1hz_piano = quantized_chroma_to_CENS(piano_chroma, 201, 50, SYNCTOOLBOX_FEATURE_RATE)[0]\n",
    "opt_chroma_shift = compute_optimal_chroma_shift(f_cens_1hz_orch, f_cens_1hz_piano)\n",
    "piano_chroma = shift_chroma_vectors(piano_chroma, opt_chroma_shift)\n",
    "\n",
    "# Synchronize with MrMsDTW\n",
    "wp = sync_via_mrmsdtw(f_chroma1=orch_chroma, \n",
    "                      f_onset1=orch_obd,\n",
    "                      f_chroma2=piano_chroma, \n",
    "                      f_onset2=piano_obd,\n",
    "                      input_feature_rate=SYNCTOOLBOX_FEATURE_RATE,\n",
    "                      step_weights=STEP_WEIGHTS, \n",
    "                      threshold_rec=THRESHOLD_REC,\n",
    "                      verbose=False)\n",
    "wp = make_path_strictly_monotonic(wp)\n",
    "\n",
    "pitch_shift_for_orch = -opt_chroma_shift % 12\n",
    "if pitch_shift_for_orch > 6:\n",
    "    pitch_shift_for_orch -= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6403f-79ed-4efd-a12a-b17bdf302d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orch_stereo, _ = librosa.load(ORCH_FILEPATH, sr=44100, mono=False)\n",
    "piano_stereo, _ = librosa.load(PIANO_FILEPATH, sr=44100, mono=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2c594-d0d5-40a7-b271-5341836f7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "orch_c1 = libtsm.pitch_shift(orch_stereo[0, :], pitch_shift_for_orch * 100, order=\"tsm-res\")  \n",
    "orch_c2 = libtsm.pitch_shift(orch_stereo[1, :], pitch_shift_for_orch * 100, order=\"tsm-res\")\n",
    "\n",
    "time_map = wp.T / SYNCTOOLBOX_FEATURE_RATE * 44100\n",
    "time_map[time_map[:, 0] > len(orch_c1), 0] = len(orch_c1) - 1 \n",
    "time_map[time_map[:, 1] > len(piano_stereo[0, :]), 1] = len(piano_stereo[0, :]) - 1\n",
    "\n",
    "# Apply Time-Scale Modification\n",
    "orch_c1 = libtsm.hps_tsm(orch_c1, time_map)\n",
    "orch_c2 = libtsm.hps_tsm(orch_c2, time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6770d4-af9c-4c25-8822-8b5d020353d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to the output directory\n",
    "sf.write(os.path.join(OUT_DIR, 'piano.wav'), piano.T, 44100)\n",
    "sf.write(os.path.join(OUT_DIR, 'orchestra.wav'), np.hstack([orch_c1, orch_c2]), 44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
